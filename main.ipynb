{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfb5e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db3a79",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "# Load Google Sheet as a CSV\n",
    "df = pd.read_csv(\"cofounder_profiles_original.csv\")\n",
    "# Step 1: Clean and rename columns\n",
    "df.columns = df.columns.str.strip()  # remove leading/trailing whitespace\n",
    "df = df.rename(columns={\n",
    "    \"Vorname\": \"first_name\",\n",
    "    \"Nachname\": \"last_name\",\n",
    "    \"Wohnort\": \"location\",\n",
    "    \"Aktuelle Branche/Industrie\": \"current_industry\",\n",
    "    \"Brancheninteresse\": \"industry_interest\",\n",
    "    \"Gr√ºndungsstatus\": \"startup_status\",\n",
    "    \"Skills/Hintergrund\": \"skills_background\",\n",
    "    \"Ich suche...\": \"looking_for_1\",\n",
    "    \"Ich suche..\": \"looking_for_2\",\n",
    "    \"Ich biete...\": \"offering_1\",\n",
    "    \"Ich biete..\": \"offering_2\",\n",
    "    \"LinkedIn-Profil\": \"linkedin\",\n",
    "    \"E-Mail-Adresse\": \"email\",\n",
    "    \"Telefonnummer\": \"phone\",\n",
    "    \"Zeitstempel\": \"timestamp\"\n",
    "})\n",
    "\n",
    "# Step 2: Combine the 'looking for' and 'offering' columns\n",
    "df[\"looking_for\"] = df[\"looking_for_1\"].fillna(\"\") + \" \" + df[\"looking_for_2\"].fillna(\"\")\n",
    "df[\"offering\"] = df[\"offering_1\"].fillna(\"\") + \" \" + df[\"offering_2\"].fillna(\"\")\n",
    "\n",
    "# Step 3: Drop the old columns (optional)\n",
    "df = df.drop(columns=[\"looking_for_1\", \"looking_for_2\", \"offering_1\", \"offering_2\"])\n",
    "\n",
    "# Step 4: Replace NaNs with empty strings\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Step 5: Clean the text data\n",
    "def sanitize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = unescape(text)  # Convert HTML entities (e.g., &amp;) to normal characters\n",
    "    text = re.sub(r'<[^>]*?>', '', text)  # Remove any HTML tags\n",
    "    text = re.sub(r'[\\r\\n]+', ' ', text)  # Replace newlines with spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces\n",
    "    return text.strip()\n",
    "# Apply the cleaning function to all relevant columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(sanitize_text)\n",
    "\n",
    "# Step 6: Remove duplicates based on 'email' and 'phone' columns\n",
    "df = df.drop_duplicates(subset=[\"email\", \"phone\"], keep=\"first\")\n",
    "\n",
    "# Step 7: Save the cleaned DataFrame to a new CSV file\n",
    "df.to_csv(\"cofounder_profiles_cleaned.csv\", index=False)\n",
    "\n",
    "# Optional: preview the cleaned DataFrame\n",
    "print(df.head(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a99624",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Embedding the data\n",
    "def embed_text(texts, prefix=\"\"):\n",
    "    return [model.encode(f\"{prefix} {t}\", convert_to_numpy=True) for t in texts]\n",
    "\n",
    "# Embed 'looking_for' as queries\n",
    "df[\"embedding_looking_for\"] = embed_text(df[\"looking_for\"], prefix=\"query:\")\n",
    "\n",
    "# Embed 'offering' as passages\n",
    "df[\"embedding_offering\"] = embed_text(df[\"offering\"], prefix=\"passage:\")\n",
    "\n",
    "# Embed industry fields\n",
    "df[\"embedding_current_industry\"] = embed_text(df[\"current_industry\"], prefix=\"info:\")\n",
    "df[\"embedding_industry_interest\"] = embed_text(df[\"industry_interest\"], prefix=\"info:\")\n",
    "\n",
    "# Embed skills\n",
    "df[\"embedding_skills\"] = embed_text(df[\"skills_background\"], prefix=\"info:\")\n",
    "df.to_csv(\"cofounder_profiles_embeddings.csv\", index=False)\n",
    "df.to_pickle(\"embedded_profiles.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24798759",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load your embedded DataFrame (if not already loaded)\n",
    "df = pd.read_pickle(\"embedded_profiles.pkl\")\n",
    "\n",
    "def compute_match_score(\n",
    "    row_a,\n",
    "    row_b,\n",
    "    weight_main=0.6,\n",
    "    weight_industry=0.15,\n",
    "    weight_skills=0.2,\n",
    "    location_bonus=0.05\n",
    "):\n",
    "    # --- Main match (looking for vs offering)\n",
    "    sim_a = cosine_similarity(\n",
    "        row_a[\"embedding_looking_for\"].reshape(1, -1),\n",
    "        row_b[\"embedding_offering\"].reshape(1, -1)\n",
    "    )[0][0]\n",
    "\n",
    "    sim_b = cosine_similarity(\n",
    "        row_b[\"embedding_looking_for\"].reshape(1, -1),\n",
    "        row_a[\"embedding_offering\"].reshape(1, -1)\n",
    "    )[0][0]\n",
    "\n",
    "    score_main = (sim_a + sim_b) / 2 * weight_main\n",
    "\n",
    "    # --- Industry match\n",
    "    if weight_industry != 0:\n",
    "        industry_sim = cosine_similarity(\n",
    "            row_a[\"embedding_industry_interest\"].reshape(1, -1),\n",
    "            row_b[\"embedding_current_industry\"].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        score_industry = industry_sim * weight_industry\n",
    "    else:\n",
    "        # If weight_industry is 0, we don't want to compute the industry similarity\n",
    "        score_industry = 0\n",
    "\n",
    "    # --- Skills match (symmetric, how similar their skills are)\n",
    "    if weight_skills != 0:\n",
    "        skills_sim = cosine_similarity(\n",
    "            row_a[\"embedding_skills\"].reshape(1, -1),\n",
    "            row_b[\"embedding_skills\"].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        score_skills = skills_sim * weight_skills\n",
    "    else:\n",
    "        # If weight_skills is 0, we don't want to compute the skills similarity\n",
    "        score_skills = 0\n",
    "\n",
    "    # --- Optional location bonus\n",
    "    bonus = 0\n",
    "    if row_a[\"location\"] and row_b[\"location\"]:\n",
    "        if row_a[\"location\"].strip().lower() == row_b[\"location\"].strip().lower():\n",
    "            bonus += location_bonus\n",
    "\n",
    "    # --- Total score\n",
    "    total_score = score_main + score_industry + score_skills + bonus\n",
    "\n",
    "    return total_score\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx_a, row_a in df.iterrows():\n",
    "    for idx_b, row_b in df.iterrows():\n",
    "        if idx_a == idx_b:\n",
    "            continue  # skip self\n",
    "\n",
    "        score = compute_match_score(row_a, row_b)\n",
    "\n",
    "        results.append({\n",
    "            \"person_a\": row_a[\"first_name\"] + \" \" + row_a[\"last_name\"],\n",
    "            \"person_b\": row_b[\"first_name\"] + \" \" + row_b[\"last_name\"],\n",
    "            \"score\": score,\n",
    "            \"email_a\": row_a[\"email\"],\n",
    "            \"email_b\": row_b[\"email\"],\n",
    "            \"location_a\": row_a[\"location\"],\n",
    "            \"location_b\": row_b[\"location\"]\n",
    "        })\n",
    "\n",
    "# Create a DataFrame of match scores\n",
    "match_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort best matches\n",
    "match_df = match_df.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "# Optional: top N matches per person\n",
    "top_matches = match_df.groupby(\"person_a\").head(5)\n",
    "top_matches.to_csv(\"top_matches.csv\", index=False)\n",
    "top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d533938",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def compute_group_score(group_rows, **kwargs):\n",
    "    \"\"\"Compute average pairwise match score for a group of rows\"\"\"\n",
    "    scores = []\n",
    "    for a, b in combinations(group_rows, 2):\n",
    "        score = compute_match_score(a, b, **kwargs)\n",
    "        scores.append(score)\n",
    "    return sum(scores) / len(scores)  # average of pairwise scores\n",
    "\n",
    "\n",
    "\n",
    "def score_group_helper(group, kwargs):\n",
    "    score = compute_group_score(group, **kwargs)\n",
    "    group_info = {\n",
    "        f\"name_{i+1}\": f\"{r['first_name']} {r['last_name']}\" for i, r in enumerate(group)\n",
    "    }\n",
    "    group_info.update({\n",
    "        f\"email_{i+1}\": r.get(\"email\", \"\") for i, r in enumerate(group)\n",
    "    })\n",
    "    group_info[\"score\"] = score\n",
    "    # Also include indexes or unique id for reference per person\n",
    "    group_info[\"person_ids\"] = [r['email'] for r in group]  # or any unique identifier per person\n",
    "    return (score, group_info)\n",
    "\n",
    "def find_top_n_per_person(df, group_number=2, top_n=5, max_workers=None, **kwargs):\n",
    "    rows = [row._asdict() for row in df.itertuples(index=False)]\n",
    "    all_groups = list(combinations(rows, group_number))\n",
    "\n",
    "    if max_workers is None:\n",
    "        max_workers = os.cpu_count() or 1\n",
    "\n",
    "    # Dictionary: person_id -> min-heap of (score, group_info)\n",
    "    person_matches = defaultdict(list)\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(score_group_helper, group, kwargs): group for group in all_groups}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Computing groups\"):\n",
    "            score, group_info = future.result()\n",
    "            person_ids = group_info[\"person_ids\"]\n",
    "\n",
    "            for pid in person_ids:\n",
    "                heap = person_matches[pid]\n",
    "                if len(heap) < top_n:\n",
    "                    heapq.heappush(heap, (score, group_info))\n",
    "                else:\n",
    "                    if score > heap[0][0]:\n",
    "                        heapq.heapreplace(heap, (score, group_info))\n",
    "\n",
    "    # Prepare results: flatten to one row per person per match\n",
    "    records = []\n",
    "    for pid, matches in person_matches.items():\n",
    "        for score, group_info in sorted(matches, key=lambda x: x[0], reverse=True):\n",
    "            # Include person id, score, and group info\n",
    "            record = {\n",
    "                \"person_id\": pid,\n",
    "                \"score\": score,\n",
    "            }\n",
    "            record.update(group_info)\n",
    "            records.append(record)\n",
    "\n",
    "    df_results = pd.DataFrame(records)\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcad95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(f\"Detected CPU cores: {os.cpu_count()}\")\n",
    "max_workers = os.cpu_count() - 2 if os.cpu_count() > 2 else 1\n",
    "top_groups_df = find_top_n_per_person(df, group_number=3, top_n=5, max_workers=max_workers)\n",
    "\n",
    "print(top_groups_df.head())\n",
    "\n",
    "# Save to CSV\n",
    "top_groups_df.to_csv(\"top_cofounder_groups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eda805",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "top_groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926dd042",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_top_matches_for_person(df, target_email, group_size=2, top_n=5, **kwargs):\n",
    "    # Convert DataFrame rows to dicts for processing\n",
    "    rows = [row._asdict() for row in df.itertuples(index=False)]\n",
    "\n",
    "    # Find the target person\n",
    "    target = next((row for row in rows if row[\"email\"] == target_email), None)\n",
    "    if not target:\n",
    "        raise ValueError(f\"No person found with email: {target_email}\")\n",
    "\n",
    "    # Prepare pool of other participants\n",
    "    others = [r for r in rows if r[\"email\"] != target_email]\n",
    "\n",
    "    # Generate all possible groups including the target\n",
    "    all_groups = [tuple([target] + list(comb)) for comb in combinations(others, group_size - 1)]\n",
    "\n",
    "    # Score and keep top_n matches using a min-heap\n",
    "    heap = []\n",
    "    for group in tqdm(all_groups, desc=\"Scoring groups\"):\n",
    "        score = compute_group_score(group, **kwargs)\n",
    "\n",
    "        group_info = {\n",
    "            f\"name_{i+1}\": f\"{r['first_name']} {r['last_name']}\" for i, r in enumerate(group)\n",
    "        }\n",
    "        group_info.update({\n",
    "            f\"email_{i+1}\": r.get(\"email\", \"\") for i, r in enumerate(group)\n",
    "        })\n",
    "        group_info[\"score\"] = score\n",
    "\n",
    "        if len(heap) < top_n:\n",
    "            heapq.heappush(heap, (score, group_info))\n",
    "        else:\n",
    "            if score > heap[0][0]:\n",
    "                heapq.heapreplace(heap, (score, group_info))\n",
    "\n",
    "    # Sort results by descending score\n",
    "    top_groups = [x[1] for x in sorted(heap, key=lambda x: x[0], reverse=True)]\n",
    "    df_top_groups = pd.DataFrame(top_groups)\n",
    "\n",
    "    return df_top_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29941e2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "top_matches = find_top_matches_for_person(\n",
    "    df,\n",
    "    target_email=\"jamal.alkharrat@gmail.com\",\n",
    "    group_size=2,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(top_matches)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
